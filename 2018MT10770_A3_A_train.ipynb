{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018MT10770_A3_A_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWjwfx8T5OAJ"
      },
      "source": [
        "Make a copy of this notebook and rename using your USERID in the following format, 2017CSZ8058\n",
        "\n",
        "Give read access to keshavkolluru@gmail.com, vishalsaley114@gmail.com and kartikeya.badola@gmail.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spAvH1fF0Rhg"
      },
      "source": [
        "## DONT CHANGE THIS CELL\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrnkLN2LzlDB"
      },
      "source": [
        "## Import relevant packages\n",
        "\n",
        "import os\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.optim as O\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import logging\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from pdb import set_trace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr3ok6g51O_d"
      },
      "source": [
        "## Various utility functions\n",
        "\n",
        "def parse_args():\n",
        "\tparser = ArgumentParser(description='NLI Baseline')\n",
        "\tparser.add_argument('--dataset', '-d', type=str, default='mnli')\n",
        "\tparser.add_argument('--model', '-m', type=str, default='bilstm')\n",
        "\tparser.add_argument('--gpu', type=int, default=0)\n",
        "\tparser.add_argument('--batch_size', type=int, default=128)\n",
        "\tparser.add_argument('--embed_dim', type=int, default=300)\n",
        "\tparser.add_argument('--d_hidden', type=int, default=200)\n",
        "\tparser.add_argument('--dp_ratio', type=int, default=0.2)\n",
        "\tparser.add_argument('--epochs', type=int, default=20)\n",
        "\tparser.add_argument('--lr', type=float, default=0.001)\n",
        "\tparser.add_argument('--combine', type=str, default='cat')\n",
        "\tparser.add_argument('--results_dir', type=str, default='results')\n",
        "\treturn check_args(parser.parse_args())\n",
        "\n",
        "\"\"\"checking arguments\"\"\"\n",
        "def check_args(args):\n",
        "\t# --result_dir\n",
        "\tcheck_folder(os.path.join(args.results_dir, args.model, args.dataset))\n",
        "\n",
        "\t# --epoch\n",
        "\ttry:\n",
        "\t\t\tassert args.epochs >= 1\n",
        "\texcept:\n",
        "\t\t\tprint('number of epochs must be larger than or equal to one')\n",
        "\n",
        "\t# --batch_size\n",
        "\ttry:\n",
        "\t\t\tassert args.batch_size >= 1\n",
        "\texcept:\n",
        "\t\t\tprint('batch size must be larger than or equal to one')\n",
        "\treturn args\n",
        "\n",
        "def get_device(gpu_no):\n",
        "\tif torch.cuda.is_available():\n",
        "\t\ttorch.cuda.set_device(gpu_no)\n",
        "\t\treturn torch.device('cuda:{}'.format(gpu_no))\n",
        "\telse:\n",
        "\t\treturn torch.device('cpu')\n",
        "\n",
        "def makedirs(name):\n",
        "\t\"\"\"helper function for python 2 and 3 to call os.makedirs()\n",
        "\t\tavoiding an error if the directory to be created already exists\"\"\"\n",
        "\n",
        "\timport os, errno\n",
        "\n",
        "\ttry:\n",
        "\t\tos.makedirs(name)\n",
        "\texcept OSError as ex:\n",
        "\t\tif ex.errno == errno.EEXIST and os.path.isdir(name):\n",
        "\t\t\t# ignore existing directory\n",
        "\t\t\tpass\n",
        "\t\telse:\n",
        "\t\t\t# a different error happened\n",
        "\t\t\traise\n",
        "\n",
        "def check_folder(log_dir):\n",
        "\tif not os.path.exists(log_dir):\n",
        "\t\tos.makedirs(log_dir)\n",
        "\treturn log_dir\n",
        "\n",
        "def get_logger(args, phase):\n",
        "\tlogging.basicConfig(level=logging.INFO, \n",
        "\t\t\t\t\t\t\t\t\t\t\t\tfilename = \"{}/{}/{}/{}.log\".format(args.results_dir, args.model, args.dataset, phase),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tformat = '%(asctime)s - %(message)s', \n",
        "\t\t\t\t\t\t\t\t\t\t\t\tdatefmt='%d-%b-%y %H:%M:%S')\n",
        "\treturn logging.getLogger(phase)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14EjR4tmz2x5"
      },
      "source": [
        "## Basic training loop\n",
        "\n",
        "class Train():\n",
        "\tdef __init__(self):\n",
        "\t\tprint(\"program execution start: {}\".format(datetime.datetime.now()))\n",
        "\t\tself.args = parse_args()\n",
        "\t\tself.device = get_device(self.args.gpu)\n",
        "\t\tself.logger = get_logger(self.args, \"train\")\n",
        "\t\tself.logger.info(\"Arguments: {}\".format(self.args))\n",
        "\t\t\n",
        "\t\tdataset_options = {\n",
        "\t\t\t\t\t\t\t\t\t\t\t'batch_size': self.args.batch_size, \n",
        "\t\t\t\t\t\t\t\t\t\t\t'device': self.device\n",
        "\t\t\t\t\t\t\t\t\t\t}\n",
        "\n",
        "    ## TODO: Load your own dataset\n",
        "\t\tself.dataset = None\n",
        "\t\t\n",
        "    ## TODO: Load your own model\n",
        "\t\tself.model = None\n",
        "\t\t\n",
        "\t\tself.model.to(self.device)\n",
        "\t\tself.criterion = nn.CrossEntropyLoss(reduction = 'sum')\n",
        "\t\tself.opt = O.Adam(self.model.parameters(), lr = self.args.lr)\n",
        "\t\tself.best_val_acc = None\n",
        "\t\tself.scheduler = StepLR(self.opt, step_size=5, gamma=0.5)\n",
        "\n",
        "\t\tprint(\"resource preparation done: {}\".format(datetime.datetime.now()))\n",
        "\n",
        "\tdef result_checkpoint(self, epoch, train_loss, val_loss, train_acc, val_acc, took):\n",
        "\t\tif self.best_val_acc is None or val_acc > self.best_val_acc:\n",
        "\t\t\tself.best_val_acc = val_acc\n",
        "\t\t\ttorch.save({\n",
        "\t\t\t\t'accuracy': self.best_val_acc,\n",
        "\t\t\t\t'options': self.model_options,\n",
        "\t\t\t\t'model_dict': self.model.state_dict(),\n",
        "\t\t\t}, '{}/{}/{}/best-{}-{}-params.pt'.format(self.args.results_dir, self.args.model, self.args.dataset, self.args.model, self.args.dataset))\n",
        "\t\tself.logger.info('| Epoch {:3d} | train loss {:5.2f} | train acc {:5.2f} | val loss {:5.2f} | val acc {:5.2f} | time: {:5.2f}s |'\n",
        "\t\t\t\t.format(epoch, train_loss, train_acc, val_loss, val_acc, took))\n",
        "\t\n",
        "\tdef train(self):\n",
        "\t\tself.model.train(); self.dataset.train_iter.init_epoch()\n",
        "\t\tn_correct, n_total, n_loss = 0, 0, 0\n",
        "\t\tfor batch_idx, batch in enumerate(self.dataset.train_iter):\n",
        "\t\t\tself.opt.zero_grad()\n",
        "\t\t\tanswer = self.model(batch)\n",
        "\t\t\tloss = self.criterion(answer, batch.label)\n",
        "\t\t\t\n",
        "\t\t\tn_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
        "\t\t\tn_total += batch.batch_size\n",
        "\t\t\tn_loss += loss.item()\n",
        "\t\t\t\n",
        "\t\t\tloss.backward(); self.opt.step()\n",
        "\t\ttrain_loss = n_loss/n_total\n",
        "\t\ttrain_acc = 100. * n_correct/n_total\n",
        "\t\treturn train_loss, train_acc\n",
        "\n",
        "\tdef validate(self):\n",
        "\t\tself.model.eval(); self.dataset.dev_iter.init_epoch()\n",
        "\t\tn_correct, n_total, n_loss = 0, 0, 0\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tfor batch_idx, batch in enumerate(self.dataset.dev_iter):\n",
        "\t\t\t\tanswer = self.model(batch)\n",
        "\t\t\t\tloss = self.criterion(answer, batch.label)\n",
        "\t\t\t\t\n",
        "\t\t\t\tn_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
        "\t\t\t\tn_total += batch.batch_size\n",
        "\t\t\t\tn_loss += loss.item()\n",
        "\n",
        "\t\t\tval_loss = n_loss/n_total\n",
        "\t\t\tval_acc = 100. * n_correct/n_total\n",
        "\t\t\treturn val_loss, val_acc\n",
        "\n",
        "\tdef execute(self):\n",
        "\t\tprint(\" [*] Training starts!\")\n",
        "\t\tprint('-' * 99)\n",
        "\t\tfor epoch in range(1, self.args.epochs+1):\n",
        "\t\t\tstart = time.time()\n",
        "\n",
        "\t\t\ttrain_loss, train_acc = self.train()\n",
        "\t\t\tval_loss, val_acc = self.validate()\n",
        "\t\t\tself.scheduler.step()\n",
        "\t\t\t\n",
        "\t\t\ttook = time.time()-start\n",
        "\t\t\tself.result_checkpoint(epoch, train_loss, val_loss, train_acc, val_acc, took)\n",
        "\n",
        "\t\t\tprint('| Epoch {:3d} | train loss {:5.2f} | train acc {:5.2f} | val loss {:5.2f} | val acc {:5.2f} | time: {:5.2f}s |'.format(\n",
        "\t\t\t\tepoch, train_loss, train_acc, val_loss, val_acc, took))\n",
        "\t\tself.finish()\n",
        "\n",
        "\tdef finish(self):\n",
        "\t\tself.logger.info(\"[*] Training finished!\\n\\n\")\n",
        "\t\tprint('-' * 99)\n",
        "\t\tprint(\" [*] Training finished!\")\n",
        "\t\tprint(\" [*] Please find the saved model and training log in results_dir\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM2QDq2iz-h7"
      },
      "source": [
        "## Start training\n",
        "task = Train()\n",
        "task.execute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-j7z1e6OjGO"
      },
      "source": [
        "## Zip the final model and all the required files, such as vocabulary\n",
        "# Replace USERID with your own, such as 2017CSZ8058\n",
        "!zip -r USERID_A_model.zip **\n",
        "\n",
        "## Upload it to Google drive and ensure that the testing notebook uses the correct link"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}